---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Volatility Spillovers from US to SA Markets"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Some Guy}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Ruan Geldenhuys" # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellenbosch University, Stellenbosch, South Africa" # First Author's Affiliation
Email1: "22550801\\@sun.ac.za" # First Author's Email address

Author2: "Nico Katzke"
Ref2: "Stellenbosch University, Stellenbosch, South Africa"
Email2: "nfkatzke\\@gmail.com"
CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

# If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
keywords: "Multivariate GARCH \\sep Spillovers" # Use \\sep to separate

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  I investigate the relationship between the voaltilities of S\\&P 500 and the JSE Top 40. The purpose of this study is to investigate if this relationship changes in any significant way during the two biggest crisis periods in the last two decades, namely the Global Financial Crisis and Covid-19. I first do a stratification analysis which reveals significant evidence of these two indices sharing periods of high volatility. I then fit multiple multivariate GARCH models to further investigate the volatility relationship and find... 
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')

rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
library(readxl)
library(fmxdat)
library(tseries)
library(knitr)
library(MTS)
library(zoo)
library(ggthemes)
library(rmgarch)
library(rugarch)
library(mgarchBEKK)
library(tikzDevice)
library(moments)
library(xtable)

list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

```

<!-- ############################## -->

<!-- # Start Writing here: -->

<!-- ############################## -->

# Introduction \label{Introduction}



# Data

Three return series are used in the analysis that follows. These are the monthly returns for the S\&P 500 and the JSE Top 40, as well as thhe ZAR/USD exchange rate. The exchange rate is represented as the amount of Rands required to buy one US Dollar. Since the series is represented as a growth rate, a postive growth rate represents a depreciation of the Rand, and conversely, an appreciation of the Dollar. The returns for these 3 series' are visualised below in Figures \ref{Figure1} to \ref{Figure3}.

```{r Figure1, warning =  FALSE, fig.align = 'center', fig.cap = "S\\&P 500 Returns \\label{Figure1}", fig.ext = 'png', fig.height = 5, fig.width = 6}

global_indices <- readRDS("data/Global_Indices.rds")
local_indices <- readRDS("data/LCL_Indices.rds")
USDZAR <- readRDS("data/USDZAR.rds")

SP <- global_indices %>% #This includes rand returns
    filter(Tickers == "SPXT") %>% 
    select(c(date, Returns)) %>% 
    rename(SP500 = Returns)

lcl_index <- "J200" # I create this variable so the choice of SA index can easily be changed
JSE <- local_indices %>% 
    filter(Tickers == lcl_index) %>% 
    select(c(date, Returns)) %>% 
    rename(JSE40 = Returns)

joinedDF <- left_join(SP, JSE, by = 'date')

firstdate <- joinedDF %>%  slice(1) %>% pull(date)

ZARUSD <- USDZAR %>% 
    select(c(date, value)) %>% 
    filter(date >= firstdate) %>% 
    mutate(yearmonth = format(ymd(date), "%Y-%m")) %>% 
    group_by(yearmonth) %>% 
    mutate(ZARUSD = dplyr::last(value)/dplyr::first(value) - 1) %>% 
    filter(date == dplyr::last(date)) %>% 
    ungroup() %>% 
    slice(-1) %>% 
    select(c(date, ZARUSD))

joinedDF <- left_join(ZARUSD, joinedDF, by = 'date') 
joinedDF <- joinedDF[c(1,3,4,2)]

#Plot the returns
returnplots <- returns_plotter(joinedDF, c("S&P 500", "JSE Top 40", "USD/ZAR"))
returnplots$`S&P 500`


```

```{r Figure2, warning =  FALSE, fig.align = 'center', fig.cap = "JSE Top 40 Returns \\label{Figure2}", fig.ext = 'png', fig.height = 5, fig.width = 6}

returnplots$`JSE Top 40`

```

Not much information can be revealed through simply observing the returns over time. However, when investigating the squared returns as a measure of volatility, it is clear to see that the JSE Top 40 is substantially more volatile than the S\&P 500. This result is reinforced by Table \ref{tab1}, where the JSE showcases a standard deviation considerably higher than that of the S\&P. Interestingly, the JSE Top 40 showcases higher average monthly returns, however that comes at the cost of the increased volatility as described above. Lastly, as shown in Table \ref{tab1} the S\&P experienced the largest draw down, while the JSE experienced the largest uptick.

```{r Figure3, warning =  FALSE, fig.align = 'center', fig.cap = "ZAR/USD Returns \\label{Figure3}", fig.ext = 'png', fig.height = 5, fig.width = 6}

returnplots$`USD/ZAR`

```

```{r, results='asis'}
sumstats <- function(vec){
    mean <- mean(vec)
    median <- median(vec)
    sd <- sd(vec)
    kurtosis <- kurtosis(vec)
    skewness <- skewness(vec)
    minimum <- min(vec)
    maximum <- max(vec)
    
    result_vec <- c(mean, median, sd, kurtosis, skewness, minimum, maximum)
    return(result_vec)
}

SP_stats <- sumstats(joinedDF$SP500)
JSE_stats <- sumstats(joinedDF$JSE40)
ZARUSD_stats <- sumstats(joinedDF$ZARUSD)

stats_df <- data.frame(
    Measure = c("Mean", "Median", "Std. Dev.", "Kurtosis", "Skewness", "Minimum", "Maximum"),
    SP500 = SP_stats,
    JSE40 = JSE_stats,
    ZARUSD = ZARUSD_stats
)
colnames(stats_df) <- c("", "S&P 500", "JSE Top 40", "ZAR/USD")

table <- xtable(stats_df, caption = "Summary Statistics \\label{tab1}", digits = c(0,0,4,4,4))

  print.xtable(table,
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H',
             # scalebox = 0.3,
             comment = FALSE,
             caption.placement = 'top',
             include.rownames = FALSE
             )

```

Before GARCH models can be fitted, ARCH tests need to be conducted in order to see if controlling for conditional heteroskedasticity is appropriate. I employ two tests. First, a univariate Ljung-Box test is conducted on each series. Practically, to test for ARCH effects a simple AR(1) model is fitted for each series and then Ljung-Box tests are done on the residuals of each AR(1). Next, multivariate Portmanteau tests are conducted to incorporate all variables simultaneously. As outlined by @Tsay2014, 3 tests are tun. The results can found in the tables below

```{r, results='asis'}
ret_df <- joinedDF %>% 
    select(c(-date))


ljungbox_tests <- function(df) {
  results <- data.frame(Series = character(),
                        TestStatistic = numeric(),
                        PValue = numeric(),
                        LagOrder = numeric(),
                        stringsAsFactors = FALSE)

  for (series in names(df)) {
    # Fit AR(1) model
    model <- lm(df[[series]] ~ lag(df[[series]]), data = df, na.action = na.exclude)

    # Perform Ljung-Box test on squared residuals
    test_result <- Box.test(residuals(model)^2, lag = 12, type = "Ljung-Box", fitdf = 1)

    # Compile results
    results <- rbind(results, data.frame(Series = series,
                                         TestStatistic = test_result$statistic,
                                         PValue = test_result$p.value,
                                         LagOrder = 12))
  }

  rownames(results) <- NULL

  return(results)
}


arch_results_lb <- ljungbox_tests(ret_df)
table <- xtable(arch_results_lb, caption = "Ljung-Box Tests \\label{tab2}", digits = c(0,0,4,4,0))
print.xtable(table,
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H',
             # scalebox = 0.3,
             comment = FALSE,
             caption.placement = 'top',
             include.rownames = FALSE
             )


```
```{r, include=FALSE}
arch_results_march <- MarchTest(ret_df)
```
```{r, results='asis'}
march_df <- data.frame(
    Test <- c( "Q(m) of squared series(LM test)", "Rank-based Test", "Q_k(m) of squared series:"),
    TestStat <- c( 81.3244, 92.5271, 165.2131),
    pval <- c( 0.0001, 0.0001, 0.0001)
)
colnames(march_df)<- c("", "Test Statistic", "p-value")

table <- xtable(march_df, caption = "MV Portmanteau Tests \\label{tab3}", digits = c(0,0,4,4))
print.xtable(table,
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H',
             # scalebox = 0.3,
             comment = FALSE,
             caption.placement = 'top',
             include.rownames = FALSE
             )


```
As can be seen in Table \ref{tab2}, for the S\&P 500 and the JSE Top 40, the p-values are functionally zero. This means that we can reject the null of no ARCH effects for these series. The same does not hold for ZAR/USD exchange rate, which has a p-value greater than the critical level of 0.05. However when conducting multivariate tests, all tests report p-values that are functionally zero. As such the analysis continues with the assumption that ARCH effects are present within the data. This serves as motivation for the use of GARCH models in this essay.

# Methodology

I first perform stratification analysis on all three series to determine if periods of high or low volatility are shared across the S\\&P, the JSE and the ZAR/USD exchange rate. I then fit multiple univariate GARCH models on all three variables to determine an appropriate specification for the multivariate models to come. I then fit three multivariate GARCH models, namely a DCC model, a Go-GARCH model, and a BEKK-GARCH model. Formal definitions and explanations of these models follow below.

## DCC GARCH

Dynamic Conditional Correlation (DCC) models, developed by @Engle2002, are a class of multivariate GARCH models that allow for time varying correlation between variables. This is especially useful to study how specific time periods, like crises, affect the relationship between different stock indices and financial variables. Consider the following GARCH(1,1) model:

\begin{equation}
R_{it} = \mu_i + \epsilon_{it}, \quad \epsilon_{it} = \sigma_{it}z_{it}, \quad z_{it} \sim N(0,1) \label{eq1}
\end{equation}

In the equation above, $R_t = (R_{1t}, R_{2t}, ... R_{nt})$, for $n$ assets/variables, is a vector of asset returns at time $t$. Here $\mu_i$ is the mean return, $\epsilon_{it}$ is the residual, $\sigma_{it}^2$ is the conditional variance and $z_{it}$ is the standard normal innovation. The conditional variance $\sigma_{it}^2$ is modeled as:

\begin{equation}
\sigma_{it}^2 = \alpha_0 + \alpha_1 \epsilon_{it-1}^2 + \beta_1 \sigma_{it-1}^2 \label{eq2}
\end{equation}

To specify the DCC model, the standardized residuals are defined as $\tilde{\epsilon_t} = \left( \epsilon_{1t} / \sigma_{1t}, \ldots, \epsilon_{nt} / \sigma_{nt} \right)'$. The correlation matrix of $\tilde{\epsilon_t}$, denoted by $Q_t$, evolves over time as: 

\begin{equation}
Q_t = \bar{Q}(1 - a - b) + a \tilde{\epsilon}_{t-1}  \tilde{\epsilon}'_{t-1} + b Q_{t-1} \label{eq3}
\end{equation}

where $\bar{Q}$ is the unconditional correlation matrix of $\tilde{\epsilon_t}$. Parameters, $a$ and $b$ are positive and adhere to $a + b < 1$ to ensure stationarity. To obtain the dynamic conditional correlation, the elements of $Q_t$ are standardized. 

In order to estimate a DCC GARCH model, two steps are followed. First, to obtain $\sigma_{it}$ and $\tilde{\epsilon}_t$, a univariate GARCH is fitted for each return series. Then, secondly, the DCC parameters $a$ and $b$ are estimated using a likelihood function derived from the conditional multivariate distribution of $\tilde{\epsilon}_t$.

## GO-GARCH

Generalized Orthogonalized (GO) GARCH models are another class of multivariate GARCH models. Developed by @VanDerWeide2002, the model is based on the assumption that asset returns can be decomposed into orthogonal components, thus simplifying the modeling of their covariance structure. Note that GO-GARCH models can become computationally intensive quickly, as the number of variables in the model increases. Once again consider a a set of $n$ asset returns,  $R_t = (R_{1t}, R_{2t}, ... R_{nt})$. These returns can be expressed as a linear combination of its orthogonal components:

\begin{equation}
R_t = B_t F_t \label{eq4}
\end{equation}

Here $B_t$ is a time-varying $n \times n$ matrix of loadings and  $F_t$ are the orthogonal components, $F_t = (F_{1t}, F_{2t}, ... F_{nt})`$, that are assumed to follow a univariate GARCH process:

\begin{equation}
F_{it} = \sigma_{it}z_{it} \quad z_{it} \sim N(0,1)\label{eq5}
\end{equation}

where $\sigma^2_{it}$ is the conditional variance of $F_{it}$. In order to estimate the model, the loading matrix $B_t$ is estimated based on the observed correlation of the series', while the volatilities of the orthogonal components, $\sigma^2_{it}$, are estimated using standard GARCH procedures. 

## BEKK-GARCH

# Results

## Stratification

## DCC

## Go-GARCH

## BEKK-GARCH

# Conclusion

I hope you find this template useful. Remember, stackoverflow is your friend - use it to find answers to questions. Feel free to write me a mail if you have any questions regarding the use of this package. To cite this package, simply type citation("Texevier") in Rstudio to get the citation for @Texevier (Note that uncited references in your bibtex file will not be included in References).

<!-- Make title of bibliography here: -->

<!-- \newpage -->

\newpage

# References {.unnumbered}

::: {#refs}
:::

# Appendix {.unnumbered}

## Appendix A {.unnumbered}

Some appendix information here

## Appendix B {.unnumbered}
