---
output:
  md_document:
    variant: markdown_github
---

# Purpose

Purpose of this work folder.

Ideally store a minimum working example data set in data folder.

Add binary files in bin, and closed R functions in code. Human Readable settings files (e.g. csv) should be placed in settings/


```{r}

rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
library(readxl)
library(fmxdat)
library(tseries)
library(knitr)

list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
```
# Loading and Wrangling

This section deals with loading and wrangling the data into a usable format.
```{r}
global_indices <- readRDS("data/Global_Indices.rds")
local_indices <- readRDS("data/LCL_Indices.rds")
USDZAR <- readRDS("data/USDZAR.rds")

SP <- global_indices %>% #This includes rand returns
    filter(Tickers == "SPXT") %>% 
    select(c(date, Returns, Rand_Returns)) %>% 
    rename(SP500 = Returns)

lcl_index <- "J200" # I create this variable so the choice of SA index can easily be changed
JSE <- local_indices %>% 
    filter(Tickers == lcl_index) %>% 
    select(c(date, Returns)) %>% 
    rename(JSE40 = Returns)

joinedDF <- left_join(SP, JSE, by = 'date')


df <- joinedDF
names <- c("S&P 500", "Rand Returns", "JSE Top 40")



returns_plotter(joinedDF, c("S&P 500", "Rand Returns", "JSE Top 40"))


```

# Stratification

This analysis will first focus on seeing whether the JSE experience higher volatility when the S&P and the rand experiences higher volatility. I then investigate whether all variables experienced it during the GFC and Covid. This follows the practical

```{r}
#Winsorizing the data to reduce influence of extreme returns
Idxs <- joinedDF %>% 
    gather(Index, Returns, -date) %>% 
    mutate(Year = format(date, "%Y")) %>% 
    group_by(Index) %>% 
    mutate(Top = quantile(Returns, 0.99), Bot = quantile(Returns, 0.01)) %>% 
    mutate(Returns = ifelse(Returns > Top, Top, 
                         ifelse(Returns < Bot, Bot, Returns))) %>% 
    ungroup()

results_SP <- analyze_volatility_periods(joinedDF, "SP500", Idxs)
kableExtra::kable(results_SP$HighVol)
kableExtra::kable(results_SP$LowVol)

results_rand <- analyze_volatility_periods(joinedDF, "Rand_Returns", Idxs)
kableExtra::kable(results_rand$HighVol)
kableExtra::kable(results_rand$LowVol)

results_JSE <- analyze_volatility_periods(joinedDF, "JSE40", Idxs)
kableExtra::kable(results_JSE$HighVol)
kableExtra::kable(results_JSE$LowVol)



```


# ARCH Tests

To test for ARCH effects I create a function that fits a simple AR(1) to each return series. I then run Ljung-Box tests on the residuals of each of those models. The null of "No ARCH effects" is rejected for all three series.


```{r}
ret_df <- joinedDF %>% 
    select(c(-date))


ljungbox_tests <- function(df) {
  results <- data.frame(Series = character(),
                        TestStatistic = numeric(),
                        PValue = numeric(),
                        LagOrder = numeric(),
                        stringsAsFactors = FALSE)

  for (series in names(df)) {
    # Fit AR(1) model
    model <- lm(df[[series]] ~ lag(df[[series]]), data = df, na.action = na.exclude)

    # Perform Ljung-Box test on squared residuals
    test_result <- Box.test(residuals(model)^2, lag = 12, type = "Ljung-Box", fitdf = 1)

    # Compile results
    results <- rbind(results, data.frame(Series = series,
                                         TestStatistic = test_result$statistic,
                                         PValue = test_result$p.value,
                                         LagOrder = 12))
  }

  rownames(results) <- NULL

  return(results)
}


arch_results <- ljungbox_tests(ret_df)
kable(arch_results)

```



#GARCH modelling
```{r}
library(rmgarch)
install.packages("mgarchBEKK")
library(mgarchBEKK)

garch_df <- joinedDF %>% 
    select(c(SP500, JSE40, Rand_Returns)) 
    

estimated <- mgarchBEKK::BEKK(garch_df, params = c(1, 1, 1, 1, 1, 1,1,1,1,1,1), method = "Nelder-Mead")

## Simulate series:
simulated <- simulateBEKK(2, 1000, c(1,1))
## Prepare the matrix:
simulated <- do.call(cbind, simulated$eps)
## Estimate with default arguments:
estimated <- BEKK(simulated)
estimated$est.params
diagnoseBEKK(estimated)
```



```{r}
install.packages("MTS")
library(MTS)

x = BEKK11(garch_df)
```

